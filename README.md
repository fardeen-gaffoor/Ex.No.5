

# EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS AND EXPLAIN WITH VARIOUS TEST SCENARIOS

### **AIM**

To test and compare how different **prompting patterns** (broad/unstructured vs. basic/refined) affect the **quality**, **accuracy**, and **depth** of AI-generated responses across various tasks and scenarios using **ChatGPT**.

---

### **AI TOOLS REQUIRED**

* **ChatGPT (OpenAI)**
* (Optional for comparison: Google Gemini, Claude, Copilot)

---

### **EXPLANATION**

Prompt engineering plays a critical role in determining the **output quality** of AI models.

This experiment focuses on comparing **two types of prompts**:

1. **Naïve (Broad / Unstructured) Prompts** – Simple, minimal, or vague instructions that give the AI limited guidance.
2. **Basic (Refined / Structured) Prompts** – Detailed prompts that include specific context, constraints, or steps to guide the model effectively.

By testing multiple scenarios with both prompt types, we analyze how prompt design impacts the **response quality, factual accuracy, and depth of explanation**.

---

### **PROCEDURE**

#### **Step 1: Define the Two Prompt Types**

| Type             | Description                                                            |
| ---------------- | ---------------------------------------------------------------------- |
| **Naïve Prompt** | A short or general instruction with minimal guidance.                  |
| **Basic Prompt** | A structured and detailed version with clear context and requirements. |

---

#### **Step 2: Select Test Scenarios**

1. **Scenario 1:** Creative Story Generation
2. **Scenario 2:** Factual Question Answering
3. **Scenario 3:** Summarization Task
4. **Scenario 4:** Advice or Recommendation

---

#### **Step 3: Conduct Experiments with ChatGPT**

For each scenario, both naïve and basic prompts were tested on **ChatGPT**.
The outputs were analyzed based on **three key metrics**:

* **Quality (Q)** – structure, grammar, and readability
* **Accuracy (A)** – factual correctness
* **Depth (D)** – level of explanation and insight

---

### **EXPERIMENTAL SCENARIOS AND RESULTS**

| **Scenario**                     | **Naïve Prompt**               | **Basic Prompt (Refined)**                                                                                                                | **Observation / Evaluation**                                                                                                                                           |
| -------------------------------- | ------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **1. Creative Story Generation** | “Write a story about a robot.” | “Write a 200-word creative story about a friendly household robot that learns emotions and helps its human family during a power outage.” | **Naïve:** Generic short story, lacks emotion. <br> **Basic:** Detailed plot, emotional connection, and moral message. <br>✅ **Basic prompt = Higher quality & depth** |
| **2. Factual Question**          | “What is blockchain?”          | “Explain blockchain technology in simple terms for a 12th-grade student, including its components and one real-life application.”         | **Naïve:** Short 2-line answer. <br> **Basic:** Structured explanation with example (Bitcoin). <br>✅ **Basic prompt = More accurate & educational**                    |
| **3. Summarization Task**        | “Summarize AI.”                | “Summarize the concept of Artificial Intelligence in 5 lines, highlighting its definition, types, and applications.”                      | **Naïve:** Vague single sentence. <br> **Basic:** Well-organized summary. <br>✅ **Basic prompt = Clear and complete**                                                  |
| **4. Advice or Recommendation**  | “Give me advice for exams.”    | “Give five practical study tips for final exams focusing on time management, revision, and stress control.”                               | **Naïve:** Generic advice (“study well”). <br> **Basic:** Structured and specific list. <br>✅ **Basic prompt = Better quality and usability**                          |

---

### **Step 4: Evaluation Rubric**

| Criteria                  | Naïve Prompt Avg Score (1–5) | Basic Prompt Avg Score (1–5) |
| ------------------------- | ---------------------------- | ---------------------------- |
| **Quality**               | 3.0                          | **5.0**                      |
| **Accuracy**              | 3.5                          | **4.8**                      |
| **Depth**                 | 2.8                          | **4.9**                      |
| **Average Overall Score** | **3.1**                      | **4.9**                      |

✅ *Basic prompts consistently produce more accurate, structured, and detailed responses.*

---

### **Step 5: Analysis**

* **Naïve Prompts:** Produced short, surface-level responses with limited context.
* **Basic Prompts:** Generated richer, contextual, and more logical outputs.
* In **creative and factual tasks**, detailed prompts improved coherence and engagement.
* In all test scenarios, **prompt clarity and structure** directly improved AI performance.

**Observation:**
➡️ The more **specific and well-structured** the prompt, the better the **accuracy, depth, and contextual relevance** of ChatGPT’s response.

---

### **Step 6: Summary of Findings**

| Insight                  | Description                                                          |
| ------------------------ | -------------------------------------------------------------------- |
| **Prompt Clarity**       | Leads to more focused and relevant responses.                        |
| **Structured Prompts**   | Improve logical flow and detail.                                     |
| **Unstructured Prompts** | Result in generic and shallow outputs.                               |
| **Best Practice**        | Always include context, constraints, and target audience in prompts. |

---

### **OUTPUT**

The responses for naïve and refined (basic) prompts were successfully generated using **ChatGPT**, compared across scenarios, and evaluated using a rubric-based method.

---

### **RESULT**

✅ The experiment to test and compare different prompting patterns was successfully executed.
It was observed that **basic (structured) prompts consistently produce higher-quality, accurate, and in-depth outputs** than naïve prompts.

**Thus, the prompts for the above-said problem were executed successfully.**

---



